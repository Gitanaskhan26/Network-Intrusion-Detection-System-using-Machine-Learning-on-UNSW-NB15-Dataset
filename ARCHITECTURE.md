# ğŸ—ï¸ System Architecture

## Overview

This document provides a detailed technical architecture of the Network Intrusion Detection System.

## High-Level Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         Data Sources                         â”‚
â”‚                  (MongoDB / Local CSV)                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Data Ingestion Layer                      â”‚
â”‚  â€¢ Load UNSW-NB15 dataset                                    â”‚
â”‚  â€¢ Train/Test split                                          â”‚
â”‚  â€¢ Artifact storage                                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  Data Validation Layer                       â”‚
â”‚  â€¢ Schema validation                                         â”‚
â”‚  â€¢ Data drift detection                                      â”‚
â”‚  â€¢ Quality checks                                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                Data Transformation Layer                     â”‚
â”‚  â€¢ Feature scaling                                           â”‚
â”‚  â€¢ Encoding                                                  â”‚
â”‚  â€¢ Missing value imputation                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   Model Training Layer                       â”‚
â”‚  â€¢ Algorithm selection                                       â”‚
â”‚  â€¢ Hyperparameter tuning                                     â”‚
â”‚  â€¢ Model evaluation                                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Model Deployment                          â”‚
â”‚  â€¢ FastAPI REST API                                          â”‚
â”‚  â€¢ Docker container                                          â”‚
â”‚  â€¢ Prediction endpoint                                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Component Details

### 1. Data Ingestion Component

**Location:** `networksecurity/components/data_ingestion.py`

**Responsibilities:**
- Connect to MongoDB or read from local CSV
- Split data into training and testing sets
- Save processed data to artifact directory
- Generate data ingestion artifact metadata

**Configuration:** `DataIngestionConfig`

**Output:** `DataIngestionArtifact`

**Key Classes:**
```python
class DataIngestion:
    def __init__(self, data_ingestion_config: DataIngestionConfig)
    def initiate_data_ingestion() -> DataIngestionArtifact
```

### 2. Data Validation Component

**Location:** `networksecurity/components/data_validation.py`

**Responsibilities:**
- Validate schema against predefined schema (YAML)
- Detect data drift using statistical tests
- Check for missing values
- Validate data types and ranges
- Generate validation report

**Configuration:** `DataValidationConfig`

**Input:** `DataIngestionArtifact`

**Output:** `DataValidationArtifact`

**Key Features:**
- Schema validation from `data_schema/schema.yaml`
- Statistical drift detection
- Generates `report.yaml`

### 3. Data Transformation Component

**Location:** `networksecurity/components/data_transformation.py`

**Responsibilities:**
- Handle missing values (SimpleImputer)
- Scale numerical features (StandardScaler)
- Encode categorical features
- Create preprocessing pipeline
- Transform data to NumPy arrays
- Save preprocessing object

**Configuration:** `DataTransformationConfig`

**Input:** `DataValidationArtifact`

**Output:** `DataTransformationArtifact`

**Pipeline:**
```python
preprocessor = Pipeline([
    ('imputer', SimpleImputer(strategy='constant', fill_value=0)),
    ('scaler', StandardScaler())
])
```

### 4. Model Training Component

**Location:** `networksecurity/components/model_trainer.py`

**Responsibilities:**
- Load transformed data
- Train classification model
- Evaluate model performance
- Calculate metrics (accuracy, precision, recall, F1)
- Save trained model
- Generate classification report

**Configuration:** `ModelTrainerConfig`

**Input:** `DataTransformationArtifact`

**Output:** `ModelTrainerArtifact`

**Supported Models:**
- Random Forest Classifier
- XGBoost
- Gradient Boosting
- (Configurable)

### 5. Prediction Pipeline

**Location:** `networksecurity/pipeline/batch_prediction.py`

**Responsibilities:**
- Load preprocessing pipeline
- Load trained model
- Accept new network traffic data
- Transform input features
- Make predictions
- Return classification results

**API Endpoint:** `/predict` (POST)

## Entity Classes

### Config Entities

**Location:** `networksecurity/entity/config_entity.py`

```python
@dataclass
class TrainingPipelineConfig:
    pipeline_name: str
    artifact_dir: str
    timestamp: str

@dataclass
class DataIngestionConfig:
    ...

@dataclass
class DataValidationConfig:
    ...

@dataclass
class DataTransformationConfig:
    ...

@dataclass
class ModelTrainerConfig:
    ...
```

### Artifact Entities

**Location:** `networksecurity/entity/artifact_entity.py`

```python
@dataclass
class DataIngestionArtifact:
    trained_file_path: str
    test_file_path: str

@dataclass
class DataValidationArtifact:
    validation_status: bool
    valid_train_file_path: str
    valid_test_file_path: str
    drift_report_file_path: str

@dataclass
class DataTransformationArtifact:
    transformed_train_file_path: str
    transformed_test_file_path: str
    transformed_object_file_path: str

@dataclass
class ModelTrainerArtifact:
    trained_model_file_path: str
    train_metric_artifact: ClassificationMetricArtifact
    test_metric_artifact: ClassificationMetricArtifact
```

## Utilities

### Main Utils

**Location:** `networksecurity/utils/main_utils/utils.py`

**Functions:**
- `read_yaml_file()` - Read YAML configurations
- `write_yaml_file()` - Write YAML reports
- `save_numpy_array_data()` - Save NumPy arrays
- `load_numpy_array_data()` - Load NumPy arrays
- `save_object()` - Serialize Python objects
- `load_object()` - Deserialize Python objects

### ML Utils

**Location:** `networksecurity/utils/ml_utils/`

**Metric Module:**
- `get_classification_score()` - Calculate all metrics
- `ClassificationMetricArtifact` - Store metric results

**Model Module:**
- `NetworkModel` - Custom estimator wrapper
- Model persistence utilities

## Logging & Exception Handling

### Logging

**Location:** `networksecurity/logging/logger.py`

**Features:**
- Timestamp-based log files
- Structured logging format
- Multiple log levels (INFO, DEBUG, ERROR)
- Saved to `logs/` directory

### Exception Handling

**Location:** `networksecurity/exception/exception.py`

**Custom Exception:**
```python
class NetworkSecurityException(Exception):
    def __init__(self, error_message, error_detail: sys)
```

**Features:**
- Detailed error messages
- Line number tracking
- File path in error output
- Stack trace preservation

## Deployment Architecture

### Docker Container

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚        Docker Container              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚
â”‚  â”‚     FastAPI Application    â”‚      â”‚
â”‚  â”‚  â€¢ /predict endpoint       â”‚      â”‚
â”‚  â”‚  â€¢ Model loading           â”‚      â”‚
â”‚  â”‚  â€¢ Request validation      â”‚      â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚
â”‚                                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚
â”‚  â”‚   Trained Model Files      â”‚      â”‚
â”‚  â”‚  â€¢ model.pkl               â”‚      â”‚
â”‚  â”‚  â€¢ preprocessing.pkl       â”‚      â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚
â”‚                                      â”‚
â”‚  Port: 8080                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### CI/CD Flow

```
Git Push â†’ GitHub Actions â†’ Build Docker â†’ Push to ECR â†’ Deploy to EC2
```

**Stages:**
1. **Integration:** Lint & Test
2. **Build:** Docker image creation
3. **Push:** Upload to AWS ECR
4. **Deploy:** Pull and run on EC2

## Data Flow

```
Raw CSV â†’ MongoDB â†’ Data Ingestion â†’ Validation â†’ Transformation â†’ 
Model Training â†’ Saved Model â†’ API â†’ Predictions
```

## Security Considerations

- Environment variables for sensitive data
- MongoDB connection string in `.env`
- AWS credentials in GitHub Secrets
- Input validation in API
- Error handling without exposing internals

## Scalability

- **Horizontal Scaling:** Multiple API containers behind load balancer
- **Batch Prediction:** Process large datasets efficiently
- **Model Versioning:** Timestamp-based artifact storage
- **Cloud Storage:** S3 integration for large datasets

## Monitoring & Observability

- Application logs in `logs/` directory
- API request/response logging
- Model performance tracking
- Data drift monitoring
- Error rate tracking

---

**Last Updated:** January 2026
